[tox]
envlist = py39-airflow_2_2_3,manifest
toxworkdir = {toxinidir}/../../.tox/dbnd-databricks

[dbnd]
home = {toxinidir}/../..
# the integration tests requires more modules.
tests = tests/test_databricks_local.py
modules = {[dbnd]home}/modules
plugins = {[dbnd]home}/plugins
orchestration = {[dbnd]home}/orchestration

[testenv]
# Python 3.6+ has a number of compile-time warnings on invalid string escapes.
# PYTHONWARNINGS=d and --no-compile below make them visible during the Tox run.
install_command = pip install --no-compile {opts} {packages}

# Prevent random setuptools/pip breakages like
# https://github.com/pypa/setuptools/issues/1042 from breaking our builds.
setenv =
	VIRTUALENV_NO_DOWNLOAD = 1
	DBND_HOME = {[dbnd]home}/
	DBND__CORE__TRACKER = ['file', 'console']
	AIRFLOW_TEST_DB = {[tox]toxworkdir}/airflow-{envname}-unittests.db
	AIRFLOW__CORE__SQL_ALCHEMY_CONN = sqlite:///{env:AIRFLOW_TEST_DB}

    py39: PYTHON_VERSION=3.9
    airflow_2_2_3: AIRFLOW_VERSION=2.2.3

deps =
	-e {[dbnd]modules}/dbnd
    -e {[dbnd]orchestration}/dbnd-run[tests]
    -e {[dbnd]orchestration}/dbnd-test-scenarios
	-e {[dbnd]orchestration}/dbnd-spark
    -e {[dbnd]orchestration}/dbnd-docker

    airflow_2_2_3: apache-airflow[amazon,apache.spark]=={env:AIRFLOW_VERSION}
    airflow_2_2_3: -c https://raw.githubusercontent.com/apache/airflow/constraints-{env:AIRFLOW_VERSION}/constraints-no-providers-{env:PYTHON_VERSION}.txt
    airflow_2_2_3: apache-airflow-providers-databricks==2.2.0

allowlist_externals =
    rm

filterwarnings =
	once::Warning: Django>=1.5,<1.6
	ignore::ResourceWarning

commands =
	rm -f {env:AIRFLOW_TEST_DB}
    airflow db init
	pytest -m "not databricks_integration" --cov dbnd_databricks --junit-xml build/junit-{envname}.xml {[dbnd]tests} {posargs}
	coverage report


[testenv:manifest]
basepython = python3.9
deps = check-manifest
skip_install = true
commands = check-manifest
